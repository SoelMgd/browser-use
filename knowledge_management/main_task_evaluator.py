"""
Main script for task execution and evaluation with Browser-Use.

This script:
1. Executes a task with Browser-Use
2. Evaluates the result with an LLM evaluator
3. In case of failure, retries with the guide generated by the evaluator
4. Saves navigation graphs and success plans
"""

import asyncio
import json
import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional
from urllib.parse import urlparse

# Add project path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from dotenv import load_dotenv

# Browser-Use imports
from browser_use.agent.service import Agent
from browser_use.browser import BrowserProfile, BrowserSession
from browser_use.llm import ChatAnthropic

# Local imports
from knowledge_management.utils.history_parser import load_history_from_file, history_to_llm_messages, save_all_screenshots
from knowledge_management.utils.llm_response_parser import parse_llm_evaluation_response, ParsedLLMResponse
from knowledge_management.utils.plan_rag_manager import PlanRAGManager
from knowledge_management.utils.navigation_graph_manager import NavigationGraphManager
from knowledge_management.utils.guide_generator import GuideGenerator
from knowledge_management.prompts.eval_generation_prompts import SYSTEM_PROMPT_EVAL

# Logging configuration
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()


class TaskEvaluator:
    """Main class for task evaluation and improvement"""
    
    def __init__(self, max_attempts: int = 3):
        self.max_attempts = max_attempts
        self.api_key = os.getenv('ANTHROPIC_API_KEY')
        
        if not self.api_key:
            raise ValueError("ANTHROPIC_API_KEY not defined in environment variables")
        
        # Initialize Browser-Use
        self.browser_session = BrowserSession(
            browser_profile=BrowserProfile(
                headless=False,  # True in production
                minimum_wait_page_load_time=3,
                maximum_wait_page_load_time=10,
                viewport={'width': 1280, 'height': 1100},
                user_data_dir='~/.config/browseruse/profiles/default',
            )
        )
        
        # Initialize LLM for Browser-Use
        self.browser_llm = ChatAnthropic(
            model="claude-sonnet-4-20250514",
        )
        
        # Initialize evaluator LLM
        self.evaluator_llm = ChatAnthropic(
            model="claude-sonnet-4-20250514",
            api_key=self.api_key,
            max_tokens=6000,
            temperature=0.1
        )
        
        # Save paths
        self.navigation_graphs_dir = Path(__file__).parent / "navigation_graphs"
        self.plans_dir = Path(__file__).parent / "plans"
        self.screenshots_dir = Path(__file__).parent / "screenshots"
        self.tmp_dir = Path(__file__).parent.parent.parent / "tmp"
        
        # Create directories if needed
        self.navigation_graphs_dir.mkdir(exist_ok=True)
        self.plans_dir.mkdir(exist_ok=True)
        self.screenshots_dir.mkdir(exist_ok=True)
        self.tmp_dir.mkdir(exist_ok=True)
        
        self.rag_manager = PlanRAGManager() # Initialize RAG manager for plans
        self.nav_manager = NavigationGraphManager() # Initialize navigation graph manager
        self.guide_generator = GuideGenerator(self.api_key) # Initialize optimized guide generator
    
    def _generate_task_id(self, task: str) -> str:
        """Generate a unique ID for the task"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        task_hash = hash(task) % 10000
        return f"task_{timestamp}_{task_hash}"
    
    def _save_navigation_graph(self, navigation_graph: dict, website_url: str = None):
        """
        Save navigation graph using NavigationGraphManager
        """
        try:
            # Use NavigationGraphManager to save
            success = self.nav_manager.save_navigation_graph(navigation_graph, website_url)
            if not success:
                logger.warning("⚠️ Failed to save navigation graph")
        except Exception as e:
            logger.error(f"❌ Error saving navigation graph: {e}")
    
    def _save_successful_plan(self, task_id: str, guide: dict):
        """
        Save successful plan (now a dictionary of guides)
        """
        if not guide:
            logger.warning("⚠️ No guide to save")
            return
        
        # Save to file system (compatibility)
        filename = f"{task_id}_successful_plan.txt"
        filepath = self.plans_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            for title, content in guide.items():
                f.write(f"## {title}\n\n{content}\n\n")
        
        logger.info(f"✅ Successful plan saved: {filepath}")
        
        # Save each guide in RAG system
        for title, content in guide.items():
            try:
                success = self.rag_manager.store_successful_plan(
                    title, content, task_id
                )
                if success:
                    logger.info(f"💾 Guide '{title}' stored in RAG system")
                else:
                    logger.warning(f"⚠️ Failed to store guide '{title}' in RAG")
            except Exception as e:
                logger.error(f"❌ Error storing guide '{title}' in RAG: {e}")
    
    def _build_navigation_graph_context(self, navigation_graph: str) -> str:
        """
        Write context sentences around the navigation graph
        """
        return f"""
Here are the navigation graph which gather all the knowledge we have on this websites (pages already visited + key elements).
Use this to better understand the website structure and generate good recommendations.

Navigation graph:
{navigation_graph}

"""
    
    def _build_plans_context(self, task_title: str = None) -> str:
        """
        Write context messages around the plans retrieved from the RAG
        """
        context_parts = []
        
        if task_title:
            # Just add some context sentences around the plans
            similar_plans = self.rag_manager.find_similar_plans(task_title, top_k=10)
            if similar_plans:
                rag_context = self.rag_manager.build_context_from_similar_plans(similar_plans)
                context_parts.append(rag_context)
                context_parts.append("")  # Empty row
        
        return "\n".join(context_parts)

    def _build_failure_recommendations_context(self, verdict: str, failure_guide: str) -> str:
        """
        Write context sentences around the failure guide from last failed attempt.
        """
        return f"""
## A precedent user already tried this task before and an evaluator evaluated it, here is his verdict:

{verdict}

In order to try again efficiently and avoid common pitfalls. He wrote some recommendations that have not been tried and could be useful: 
{failure_guide}"""
    
    async def _evaluate_task_execution(self, history_file: str, task: str) -> ParsedLLMResponse:
        """Evaluate task execution with evaluator LLM"""
        try:
            # Load history
            history_data = load_history_from_file(history_file)
            
            # Convert to LLM messages
            llm_messages = history_to_llm_messages(history_data)
            
            # Create system message with task
            from browser_use.llm.messages import SystemMessage
            enhanced_system_prompt = f"""{SYSTEM_PROMPT_EVAL}

## The user try to reach this goal:
{task}

Please evaluate the user trajectory for this goal."""
            system_message = SystemMessage(content=enhanced_system_prompt)
            
            all_messages = [system_message] + llm_messages
            
            # Send to evaluator LLM
            logger.info("🔍 Evaluation in progress...")
            response = await self.evaluator_llm.ainvoke(all_messages)
            
            # Parse response
            parsed_response = parse_llm_evaluation_response(response.completion)
            
            logger.info(f"📋 Evaluation completed - Status: {parsed_response.task_label}")
            return parsed_response
            
        except Exception as e:
            logger.error(f"❌ Error during evaluation: {e}")
            raise
    
    async def _execute_task(self, task: str, enhanced_prompt: Optional[str] = None) -> str:
        """Execute a task with Browser-Use"""
        try:
            # Create agent with custom message context if provided
            agent_kwargs = {
                'task': task,
                'llm': self.browser_llm,
                'browser_session': self.browser_session,
                'validate_output': True,
                'enable_memory': False,
            }
            
            if enhanced_prompt:
                agent_kwargs['message_context'] = enhanced_prompt
            
            agent = Agent(**agent_kwargs)
            
            # Execute task
            logger.info("🚀 Executing task...")
            history = await agent.run(max_steps=25)
            
            # Save history
            history_file = self.tmp_dir / "history.json"
            history.save_to_file(str(history_file))
            
            return str(history_file)
            
        except Exception as e:
            logger.error(f"❌ Error during task execution: {e}")
            raise
    
    async def run_task_with_evaluation(self, task: str) -> dict:
        """
        Execute a task with evaluation and iterative improvement
        
        Args:
            task: The task to execute
            
        Returns:
            dict: Execution results
        """
        task_id = self._generate_task_id(task)
        logger.info(f"🎯 Starting task execution: {task_id}")
        logger.info(f"📝 Task: {task}")
        
        results = {
            'task_id': task_id,
            'task': task,
            'attempts': [],
            'final_status': None,
            'successful_plan': None
        }
        
        current_failure_guide = None
        current_task_title = None
        current_website_url = None
        current_navigation_graph = None
        current_verdict = None
        
        for attempt in range(1, self.max_attempts + 1):
            logger.info(f"\n🔄 Attempt {attempt}/{self.max_attempts}")
            
            try:
                # Generate optimized guide for this attempt !
                optimized_guide = None
                if attempt == 1:
                    # First attempt: generate guide based on existing knowledge
                    logger.info("🎯 Generating optimized guide for first attempt...")
                    optimized_guide = await self.guide_generator.generate_optimized_guide(
                        task=task,
                        website_url="http://airbnb.com",  # Default URL, will be updated after evaluation
                        task_title=None,  # Will be determined after evaluation
                        previous_guide=None,
                        attempt_count=0
                    )
                else:
                    # Subsequent attempts: use context from previous failed attempt
                    logger.info("🎯 Generating optimized guide based on previous attempt context...")
                    
                    # Build context from previous attempt
                    context_parts = []
                    
                    # Add navigation graph context if available
                    if current_navigation_graph:
                        nav_context = self._build_navigation_graph_context(json.dumps(current_navigation_graph, indent=2))
                        context_parts.append(nav_context)
                    
                    # Add plans context if available
                    if current_task_title:
                        plans_context = self._build_plans_context(current_task_title)
                        if plans_context:
                            context_parts.append(plans_context)
                    
                    # Add failure recommendations context if available
                    if current_verdict and current_failure_guide:
                        failure_context = self._build_failure_recommendations_context(current_verdict, current_failure_guide)
                        context_parts.append(failure_context)
                    
                    # Combine all context
                    combined_context = "\n".join(context_parts) if context_parts else None
                    
                    optimized_guide = await self.guide_generator.generate_optimized_guide(
                        task=task,
                        website_url=current_website_url or "http://airbnb.com",
                        task_title=current_task_title,
                        previous_guide=combined_context,
                        attempt_count=attempt - 1
                    )
                
                # Build message context with optimized guide
                message_context = None
                if optimized_guide:
                    message_context = f"""## An external evaluator would like you to try this approach that could be helpful for the task:

{optimized_guide}

Follow this guide to complete the task efficiently and avoid common pitfalls."""
                
                # Execute task
                history_file = await self._execute_task(task, message_context)
                
                # Evaluate result
                evaluation = await self._evaluate_task_execution(history_file, task)
                
                # Save navigation graph
                self._save_navigation_graph(evaluation.navigation_graph, evaluation.website_url)
                
                # Save screenshots
                screenshots = self._save_screenshots(task_id, attempt, history_file)
                
                # Update metadata for next attempts
                current_task_title = evaluation.task_title
                current_website_url = evaluation.website_url
                current_navigation_graph = evaluation.navigation_graph
                current_verdict = evaluation.verdict
                
                # Record attempt results
                attempt_result = {
                    'attempt_number': attempt,
                    'verdict': evaluation.verdict,
                    'guide': evaluation.guide,
                    'failure_guide': evaluation.failure_guide,
                    'optimized_guide': optimized_guide,
                    'website_url': evaluation.website_url,
                    'task_title': evaluation.task_title,
                    'navigation_graph_file': f"{task_id}_attempt_{attempt}_graph.json",
                    'screenshots': screenshots
                }
                results['attempts'].append(attempt_result)
                
                logger.info(f"📊 Attempt {attempt} - Status: {evaluation.task_label}")
                
                # If success, save plan in RAG and finish
                if evaluation.task_label == 'SUCCESS':
                    logger.info("✅ Task completed successfully!")
                    
                    # Save to file system (compatibility)
                    self._save_successful_plan(task_id, evaluation.guide)
                    
                    results['final_status'] = 'SUCCESS'
                    results['successful_plan'] = evaluation.guide
                    break
                
                # If failure, use failure_guide for next attempt
                elif evaluation.task_label == 'FAILURE':
                    current_failure_guide = evaluation.failure_guide
                    logger.info("⚠️ Failure detected, failure_guide updated for next attempt")
                    
                # If impossible, stop
                elif evaluation.task_label == 'IMPOSSIBLE':
                    logger.info("❌ Task impossible to accomplish")
                    results['final_status'] = 'IMPOSSIBLE'
                    break
                
            except Exception as e:
                logger.error(f"❌ Error during attempt {attempt}: {e}")
                attempt_result = {
                    'attempt_number': attempt,
                    'status': 'ERROR',
                    'error': str(e)
                }
                results['attempts'].append(attempt_result)
        
        # If all attempts failed
        if not results['final_status']:
            results['final_status'] = 'FAILURE_AFTER_MAX_ATTEMPTS'
            logger.warning("⚠️ Failure after maximum attempts")
        
        return results

    def _save_screenshots(self, task_id: str, attempt: int, history_file: str):
        """Save attempt screenshots"""
        try:
            # Load history
            history_data = load_history_from_file(history_file)
            
            # Create directory for this attempt
            screenshots_dir = self.screenshots_dir / f"{task_id}_attempt_{attempt}"
            screenshots_dir.mkdir(exist_ok=True)
            
            # Save all screenshots
            saved_files = save_all_screenshots(history_data, str(screenshots_dir))
            
            logger.info(f"📸 Screenshots saved: {len(saved_files)} images in {screenshots_dir}")
            return saved_files
            
        except Exception as e:
            logger.error(f"❌ Error saving screenshots: {e}")
            return []


async def main():
    """Main function"""

    CREDENTIALS = """ To login, use the following credentials: {
  username: 'soel@twin.so',
  password: 'Agent123456!',
}"""
    # Configuration
    TASK = """
    "Log in to your Airbnb account, save a Guest Favorite property to your wishlist, and then go to your wishlist and remove the property you previously added.
    Only use http://airbnb.com to achieve the task. Don't go to any other site. The task is achievable with just navigation from this site."
    """

    TASK = TASK + CREDENTIALS
    
    try:
        # Create evaluator
        evaluator = TaskEvaluator(max_attempts=3)
        
        # Execute task with evaluation
        results = await evaluator.run_task_with_evaluation(TASK)
        
        # Display final results
        print("\n" + "="*80)
        print("🎯 FINAL RESULTS")
        print("="*80)
        print(f"Task ID: {results['task_id']}")
        print(f"Final status: {results['final_status']}")
        print(f"Number of attempts: {len(results['attempts'])}")
        
        if results['successful_plan']:
            print(f"\n📋 Successful plan saved in: {evaluator.plans_dir}")
        
        print(f"\n📊 Navigation graphs saved in: {evaluator.navigation_graphs_dir}")
        print(f"📸 Screenshots saved in: {evaluator.screenshots_dir}")
        
        # Display attempt details
        print(f"\n📝 Attempt details:")
        for attempt in results['attempts']:
            print(f"  Attempt {attempt['attempt_number']}: {attempt.get('status', 'COMPLETED')}")
            if 'verdict' in attempt:
                print(f"    Verdict: {attempt['verdict'][:100]}...")
            if 'screenshots' in attempt and attempt['screenshots']:
                print(f"    Screenshots: {len(attempt['screenshots'])} images saved")
        
        # Display RAG statistics
        print(f"\n📚 RAG system statistics:")
        rag_stats = evaluator.rag_manager.get_plans_statistics()
        print(f"  Stored plans: {rag_stats['total_plans']}")
        print(f"  Unique websites: {rag_stats['unique_websites']}")
        if rag_stats['websites']:
            print(f"  Websites: {', '.join(rag_stats['websites'])}")
        
        # Display complete system statistics
        print(f"\n🎯 Complete system statistics:")
        system_stats = evaluator.guide_generator.get_system_statistics()
        print(f"  Total knowledge items: {system_stats['total_knowledge_items']}")
        print(f"  RAG plans: {system_stats['rag']['total_plans']}")
        print(f"  Navigation graphs: {system_stats['navigation']['total_graphs']}")
        print(f"  Covered websites: {system_stats['rag']['unique_websites'] + system_stats['navigation']['unique_websites']}")
        
    except Exception as e:
        logger.error(f"❌ Error in main: {e}", exc_info=True)


if __name__ == "__main__":
    asyncio.run(main()) 